version: '3.8'

services:
#  爬虫服务
  scrapy:
    build:
      context: .
      dockerfile: fangzhou_spider/Dockerfile
    container_name: scrapy_container
    # 挂载日志和词云目录到宿主机
    volumes:
      - ~/fangzhou/logs/scrapy:/app/logs  # 宿主机日志目录
    environment:
      - TZ=Asia/Shanghai  # 设置时区
    depends_on:
      - mongo  # 确保先启动 MongoDB
    networks:
      - fangzhou_network
    restart: "no"

#  MongoDB服务
  mongo:
    image: mongo:5.0
    container_name: mongo_container
    ports:
      - "27017:27017"  # 暴露 MongoDB 端口
    volumes:
      - ~/fangzhou/mongodb/data:/data/db  # 持久化数据存储
    networks:
      - fangzhou_network

#  Django服务
  web:
    build:
      context: .
      dockerfile: fangzhou-backend/Dockerfile
    container_name: web
    volumes:
      - fangzhou-backend/fangzhou:/app
      - static_volume:/app/static
    environment:
      - DEBUG=False
      - ALLOWED_HOSTS=web,localhost
    depends_on:
      - scrapy
    networks:
      - fangzhou_network

#  nginx服务
  nginx:
    image: nginx:1.21-alpine
    container_name: nginx
    volumes:
      - fangzhou-frontend/dist:/usr/share/nginx/html
      - static_volume:/app/static
      - nginx/nginx.conf:/etc/nginx/nginx.conf
    ports:
      - "80:80"
    depends_on:
      - web
    networks:
      - fangzhou_network

volumes:
 static_volume:





